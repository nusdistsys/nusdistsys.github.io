<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Tail At Scale | 6.824 DYOM</title><link rel=canonical href=https://nusdistsys.github.io/notes/tailatscale/><link rel=stylesheet href=https://nusdistsys.github.io/css/base.css integrity crossorigin=anonymous></head><body><nav><div class="px-2 bg-teal-700 fixed w-full"><ul class="flex h-full list-none m-0"><li class=p-4><a class="inline font-medium text-xl text-white" href=https://nusdistsys.github.io/>6.824 DYOM</a></li><li class="flex hover:bg-teal-800 h-full content-center p-4"><a class="inline font-light text-xl text-white" href=https://nusdistsys.github.io/labs/>Labs</a></li><li class="flex hover:bg-teal-800 h-full content-center p-4"><a class="inline font-light text-xl text-white" href=https://nusdistsys.github.io/notes/>Notes</a></li><li class="flex hover:bg-teal-800 h-full content-center p-4"><a class="inline font-light text-xl text-white" href=https://nusdistsys.github.io/summer/>Summer</a></li></ul></div></div></nav><main><div class="container max-w-3xl mx-auto pt-20"><article><header><span class="block py-8"><h1><a class=font-sans href=https://nusdistsys.github.io/notes/tailatscale/ rel=bookmark>Tail At Scale</a></h1><time datetime=2020-04-23T15:59:53+08:00>23 April, 2020</time></span></header><h1 id=tail-at-scale>Tail at Scale</h1><h2 id=problem>Problem</h2><p>Temporary high latency episodes may come to dominate service performance at scale. These things occur at the end of the latency curve and are problematic.</p><p>Hence, &ldquo;Latency tail-tolerant&rdquo; because we need to optimize for the &ldquo;tail&rdquo; of this latency.</p><p>The techniques focus on allowing <em>high system utilization without wasteful overprovisioning</em>.</p><h2 id=sources-of-variability>Sources of variability</h2><ul><li><p>Shared resources</p></li><li><p>Daemons</p></li><li><p>Global Resource Sharing</p></li><li><p>Maintenence</p></li></ul><p><strong>Compounded by the fact that many parallelization techniques require us to fan out and fan in</strong>.</p><p>If there is a <em>p</em> probability that a server request timesout, the probability that n servers have at least 1 timeout is 1 - (1-p) ^ n.</p><p>If p = 0.01, and n = 100, there is a 0.63 chance that it times out.</p><h2 id=technique-1-within-request-short-term>Technique 1: Within request short-term</h2><ul><li><p><em>Hedged requests</em>: issue same request to multiple replicas and use the results for whichever returns first</p></li><li><p><em>Tied requests</em>: enqueue several copies of a request in multiple servers simultaneously and allowing the servers to communicate updates of the status of these copies to each other. When request begins execution, &lsquo;cancel&rsquo; the other requests.</p></li></ul><h2 id=technique-2-cross-request-long-term-adaptations>Technique 2: Cross request long-term adaptations</h2><ul><li><p><em>Micro partitions</em>: More partitions than there are machines in the service. With dynamic assignment and load balancing. Helps with failure recovery.</p></li><li><p><em>Selective replication</em>:Identify partitions that are going to be used more and create more copies of it.</p></li><li><p><em>Latency induced probation</em>: Use latency to detect faulty machines.</p></li></ul></article></div></main></body></html>